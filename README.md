# Form and Meaning in BERT Embeddings
## Analyzing the verbal ‘te’-infinitival complement clause with optional complementizer ‘om’ in Dutch and multilingual BERT models
The encoding of different linguistic constructions by Dutch BERT models (RobBERT-2023 and BERTje) and multilingual BERT models (mBERT and EuroBERT) are examined. We compare embeddings of sentences with the verbal 'te'-infinitival complement clause with and without the optional complementizer 'om' and the verbal 'te'-infinitival complement clause without 'om' preceded by the word 'niet', which means 'not'. We divide this into two groups, one group in which the constructions differ only in form and one group in which the constructions differ in meaning as well as form. Cluster coherence is measured by the Silhouette Score and the Davies-Boudin Index, and the sentences closest to the average embedding are examined. A lot of overlap was found between the different clusters, suggesting it is hard for these models to differentiate between these constructions. However, better results were found in the group that differed in meaning as well as form than in the group that differed only in form. Better cluster coherence was also found for longer sentences than shorter sentences. The monolingual models performed better than the multilingual models. RobBERT-2023 performed best, suggesting a potential advantage for models based on the RoBERTa architecture when it comes to differentiating between linguistic constructions.
