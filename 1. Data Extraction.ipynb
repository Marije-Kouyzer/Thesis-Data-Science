{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fa0639-cc86-4dce-b636-7ee834e8b0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports + path\n",
    "import os\n",
    "import pandas as pd\n",
    "from lxml import etree\n",
    "path = '' # path to DATA folder in Lassy Groot (with \\\\ instead of \\)\n",
    "path_to_save = '' # path where csv file is to be saved (with \\\\ instead of \\)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71585f1f-0ec0-4dea-bb36-4fa0b8bdd147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# queries\n",
    "om_query = '//node[@cat=\"oti\"]'\n",
    "te_query = '//node[@cat=\"ti\" and parent::node[@cat=\"ssub\" or @cat=\"smain\" or @cat=\"sv1\"]]'\n",
    "niet_query = '//node[node[@word=\"niet\"] and node[@cat=\"ti\" and parent::node[@cat=\"ssub\" or @cat=\"smain\" or @cat=\"sv1\"]]]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bd5aed-eb73-47e8-8b76-dee542c0c45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data extraction using for loops and the queries\n",
    "folders = os.listdir(path)\n",
    "om_sentences = []\n",
    "te_sentences = []\n",
    "niet_sentences = []\n",
    "for folder in folders:\n",
    "    subpath = path + '\\\\' + folder + '\\\\ZIP'\n",
    "    subfolders = os.listdir(subpath)\n",
    "    for subfolder in subfolders:\n",
    "        if (not subfolder.endswith('.zip')):\n",
    "            path_to_files = subpath + '\\\\' + subfolder\n",
    "            files = os.listdir(path_to_files)\n",
    "            for file in files:\n",
    "                if file.endswith('.xml'):\n",
    "                    element_tree = etree.parse(path_to_files + '\\\\' + file)\n",
    "                    sentence = element_tree.xpath('//sentence')[0].text\n",
    "                    om_test = element_tree.xpath(om_query)\n",
    "                    te_test = element_tree.xpath(te_query)\n",
    "                    niet_test = element_tree.xpath(niet_query)\n",
    "                    if om_test:\n",
    "                        verb = element_tree.xpath('//node[@cat=\"oti\"]/ancestor::node[@cat=\"smain\" or @cat=\"ssub\" or @cat=\"smain\" or @cat=\"sv1\"][1]/node[@wvorm=\"pv\"]/@lemma')\n",
    "                        if (len(verb) != 0) and (not sentence.startswith('Om ')):\n",
    "                            sentence_type = element_tree.xpath('//node[@cat=\"oti\"]/ancestor::node[@cat=\"smain\" or @cat=\"ssub\" or @cat=\"smain\" or @cat=\"sv1\"][1]/@cat')\n",
    "                            subsection = element_tree.xpath('//node[@cat=\"oti\"]/descendant::*/../node[@word]/@word')\n",
    "                            subsection_positions = element_tree.xpath('//node[@cat=\"oti\"]/descendant::*/../node[@word]/@begin')\n",
    "                            sorted_subsection = [x for _, x in sorted(zip([int(i) for i in subsection_positions], subsection))]\n",
    "                            sorted_subsection.insert(0, verb[0].replace('_', ''))\n",
    "                            length_subsection = len(sorted_subsection)\n",
    "                            relevant_subsection = \" \".join(sorted_subsection).lower()\n",
    "                            om_sentences.append((sentence, verb[0], sentence_type[0], relevant_subsection, length_subsection, file))\n",
    "                    if te_test:\n",
    "                        verb = element_tree.xpath('//node[@cat=\"ti\"]/../node[@wvorm=\"pv\"]/@lemma')\n",
    "                        if (len(verb) != 0) and (not sentence.startswith('Te ')):\n",
    "                            sentence_type = element_tree.xpath('//node[@cat=\"ti\"]/parent::node[@cat=\"ssub\" or @cat=\"smain\" or @cat=\"sv1\"]/@cat')\n",
    "                            subsection = element_tree.xpath('//node[@cat=\"ti\"]/descendant::*/../node[@word]/@word')\n",
    "                            subsection_positions = element_tree.xpath('//node[@cat=\"ti\"]/descendant::*/../node[@word]/@begin')\n",
    "                            sorted_subsection = [x for _, x in sorted(zip([int(i) for i in subsection_positions], subsection))]\n",
    "                            sorted_subsection.insert(0, verb[0].replace('_', ''))\n",
    "                            length_subsection = len(sorted_subsection)\n",
    "                            relevant_subsection = \" \".join(sorted_subsection).lower()\n",
    "                            te_sentences.append((sentence, verb[0], sentence_type[0], relevant_subsection, length_subsection, file))\n",
    "                    if niet_test:\n",
    "                        verb = element_tree.xpath('//node[@cat=\"ti\"]/../node[@wvorm=\"pv\"]/@lemma')\n",
    "                        if (len(verb) != 0):\n",
    "                            sentence_type = element_tree.xpath('//node[@cat=\"ti\"]/parent::node[@cat=\"ssub\" or @cat=\"smain\" or @cat=\"sv1\"]/@cat')\n",
    "                            subsection = element_tree.xpath('//node[@cat=\"ti\"]/descendant::*/../node[@word]/@word')\n",
    "                            subsection_positions = element_tree.xpath('//node[@cat=\"ti\"]/descendant::*/../node[@word]/@begin')\n",
    "                            sorted_subsection = [x for _, x in sorted(zip([int(i) for i in subsection_positions], subsection))]\n",
    "                            sorted_subsection.insert(0, verb[0].replace('_', ''))\n",
    "                            sorted_subsection.insert(0, 'niet')\n",
    "                            length_subsection = len(sorted_subsection)\n",
    "                            relevant_subsection = \" \".join(sorted_subsection).lower()\n",
    "                            niet_sentences.append((sentence, verb[0], sentence_type[0], relevant_subsection, length_subsection, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfb7b2e-b484-4bfb-929c-32bba971a29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating and filling the DataFrame\n",
    "col = ['Category', 'Sentence', 'Verb', 'Sentence Type', 'Relevant Subsection', 'Length Relevant Subsection', 'Filename']\n",
    "df = pd.DataFrame(columns=col)\n",
    "\n",
    "for sentence, verb, type, subsection, length, filename in om_sentences:\n",
    "    df = pd.concat([df, pd.DataFrame([['oti', sentence, verb, type, subsection, length, filename]], columns=col)])\n",
    "\n",
    "for sentence, verb, type, subsection, length, filename in te_sentences:\n",
    "    df = pd.concat([df, pd.DataFrame([['ti', sentence, verb, type, subsection, length, filename]], columns=col)])\n",
    "\n",
    "for sentence, verb, type, subsection, length, filename in niet_sentences:\n",
    "    df = pd.concat([df, pd.DataFrame([['niet + ti', sentence, verb, type, subsection, length, filename]], columns=col)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33a4e39-be03-42e8-a3d2-183000d8cb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the DataFrame\n",
    "df.to_csv(path_to_save + '\\\\sentences_Lassy_Groot.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
